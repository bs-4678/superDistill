# 1. data:data0-->datan{path,from,step}
# 2. model:teacher>>student>>baseline
import os, sys, json, random, tqdm, glob
from copy import deepcopy
import subprocess
from queue import Queue
from tqdm import tqdm
import shutil

class nodeList():
    def __init__(self, nodes=[]):
        self.nodes = nodes
    
    def add_node(self, node):
        """
        æ·»åŠ èŠ‚ç‚¹åˆ°èŠ‚ç‚¹åˆ—è¡¨ã€‚
        """
        if node not in self.nodes:
            self.nodes.append(node)

class superNode():
    def __init__(self, node_list=None, sons=None, fathers=None, ancestors=None, content=None):
        self.sons = sons if sons is not None else []  # å­èŠ‚ç‚¹åˆ—è¡¨
        self.fathers = fathers if fathers is not None else []  # çˆ¶èŠ‚ç‚¹åˆ—è¡¨
        self.ancestors = ancestors if ancestors is not None else []
        self.content = content if content is not None else {}  # èŠ‚ç‚¹å†…å®¹
        self.node_list = node_list
        if self.fathers == []:  # å¦‚æœæ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼Œåˆ™å½“å‰èŠ‚ç‚¹ä¸ºæ ¹èŠ‚ç‚¹
            self.fathers = [self]  # æ ¹èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ä¸ºè‡ªå·±
            self.ancestors = [self]  # æ ¹èŠ‚ç‚¹æ²¡æœ‰ç¥–å…ˆèŠ‚ç‚¹
            self.node_list = nodeList([self]) if self.node_list is None else self.node_list  # å¦‚æœæ²¡æœ‰èŠ‚ç‚¹åˆ—è¡¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„èŠ‚ç‚¹åˆ—è¡¨
        elif self.node_list is None:  # å¦‚æœæ²¡æœ‰èŠ‚ç‚¹åˆ—è¡¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„èŠ‚ç‚¹åˆ—è¡¨
            self.node_list = fathers[0].node_list
            self.node_list.add_node(self)
        for father in self.fathers:
            father.sons.append(self)  # å°†å½“å‰èŠ‚ç‚¹æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹åˆ—è¡¨ä¸­
            self.ancestors += father.ancestors  # ç¥–å…ˆèŠ‚ç‚¹åˆ—è¡¨
        self.ancestors = list(set(self.ancestors))  # å»é‡ç¥–å…ˆèŠ‚ç‚¹åˆ—è¡¨
    
    def get_all_content(self, index=None):
        """
        è·å–èŠ‚ç‚¹çš„æ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬å­èŠ‚ç‚¹ã€çˆ¶èŠ‚ç‚¹ã€ç¥–å…ˆèŠ‚ç‚¹å’Œå½“å‰èŠ‚ç‚¹å†…å®¹ã€‚
        """
        all_content = {
            "sons": self.sons,
            "fathers": self.fathers,
            "ancestors": self.ancestors,
            "content": self.content,
        }
        return all_content

    def save_content(self, path):
        """
        ä¿å­˜èŠ‚ç‚¹å†…å®¹åˆ°æŒ‡å®šè·¯å¾„ã€‚
        """
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(self.get_all_content(), f, ensure_ascii=False, indent=4)

    def save_all(self, path):
        """
        ä¿å­˜èŠ‚ç‚¹çš„æ•´ä¸ªæ—è°±ä¸º jsonï¼Œä»ç¥–å…ˆèŠ‚ç‚¹å¼€å§‹ã€‚åŒæ—¶åœ¨jsonæœ€åæŒ‡æ˜å½“å‰èŠ‚ç‚¹ã€‚
        """
        genealogy = []
        for node in self.node_list.nodes:
            genealogy.append({
                "sons": [self.node_list.nodes.index(son) for son in node.sons],
                "fathers": [self.node_list.nodes.index(father) for father in node.fathers],
                "ancestors": [self.node_list.nodes.index(ancestor) for ancestor in node.ancestors],
                "content": node.content
            })
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(genealogy, f, ensure_ascii=False, indent=4)

    def load_all(self, path):
        """
        æ¢å¤èŠ‚ç‚¹çš„æ•´ä¸ªæ—è°±ï¼Œä»ç¥–å…ˆèŠ‚ç‚¹å¼€å§‹ã€‚è¿”å›å…¨éƒ¨èŠ‚ç‚¹ï¼Œå½“å‰èŠ‚ç‚¹åœ¨ç¬¬ä¸€ä½ã€‚
        """
        genealogy = []
        with open(path, 'r', encoding='utf-8') as f:
            nodes = nodeList(json.load(f))  # ä»æ–‡ä»¶ä¸­åŠ è½½æ—è°±æ•°æ®
        for node_content in nodes.nodes:
            node = superNode(
                sons=[],
                fathers=[],
                ancestors=[],
                node_list=genealogy,
                content=node_content['content']
            )
            node.sons=node_content['sons']
            node.fathers=node_content['fathers']
            node.ancestors=node_content['ancestors']
            genealogy.append(node)  # åˆ›å»ºèŠ‚ç‚¹å¯¹è±¡å¹¶æ·»åŠ åˆ°æ—è°±åˆ—è¡¨ä¸­

        for node in genealogy:            # è®¾ç½®å­èŠ‚ç‚¹
            node.sons = [genealogy[j] for j in node.sons]
            # è®¾ç½®çˆ¶èŠ‚ç‚¹
            fathers = []
            for j in node.fathers:
                if type(j) == int:  # å¦‚æœæ˜¯ç´¢å¼•
                    fathers.append(genealogy[j])
                else:  # å¦‚æœæ˜¯èŠ‚ç‚¹å¯¹è±¡
                    fathers.append(j)
            node.fathers = fathers
            # è®¾ç½®ç¥–å…ˆèŠ‚ç‚¹
            ancestors = []
            for j in node.ancestors:
                if type(j) == int:  # å¦‚æœæ˜¯ç´¢å¼•
                    ancestors.append(genealogy[j])
                else:  # å¦‚æœæ˜¯èŠ‚ç‚¹å¯¹è±¡
                    ancestors.append(j)
            node.ancestors = ancestors
            node.node_list = nodeList(genealogy)  # è®¾ç½®èŠ‚ç‚¹åˆ—è¡¨
        return genealogy[0]
    
    def show_content_only(self):
        """
        æ‰“å°å½“å‰èŠ‚ç‚¹çš„å†…å®¹ã€‚
        """
        print(f"Node Content: {self.content}")

    def show(self, node=None):
        """
        æ‰“å°å½“å‰èŠ‚ç‚¹çš„å†…å®¹ã€‚
        """
        if node is None:
            node = self
        print(f"Node Content: {node.content}")
        print(f"Sons: ")
        for son in node.sons:
            son.show_content_only()
        print(f"Fathers: ")
        for father in node.fathers:
            father.show_content_only()
        print(f"Ancestors: ")
        for ancestor in node.ancestors:
            ancestor.show_content_only()
        print(f"Node ID: {self.node_list.nodes.index(node)}")
        # print(f"Sons: {son.show_content_only()}" for son in node.sons)
        # print(f"Fathers: {father.show_content_only()}" for father in node.fathers)
        # print(f"Ancestors: {ancestor.show_content_only()}" for ancestor in node.ancestors)
        # print(f"Node ID: {self.node_list.nodes.index(node)}")
    
    def show_all(self):
        """
        æ‰“å°å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬å­èŠ‚ç‚¹ã€çˆ¶èŠ‚ç‚¹ã€ç¥–å…ˆèŠ‚ç‚¹å’Œå½“å‰èŠ‚ç‚¹å†…å®¹ã€‚
        """
        for node in self.node_list.nodes:
            self.show(node)
            print("-" * 40)

    def delete_node(self):
        """
        åˆ é™¤å½“å‰èŠ‚ç‚¹ï¼Œå¹¶ä»çˆ¶èŠ‚ç‚¹å’Œå­èŠ‚ç‚¹ä¸­ç§»é™¤ã€‚
        ä¸æ¨èä½¿ç”¨ï¼Œå› ä¸ºä¼šç ´åèŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ã€‚å¯¼è‡´ node_list ç¢ç‰‡åŒ–
        """
        for father in self.fathers:
            father.sons.remove(self)
        for son in self.sons:
            son.fathers.remove(self)
        self.node_list.nodes.remove(self)  # ä»èŠ‚ç‚¹åˆ—è¡¨ä¸­ç§»é™¤å½“å‰èŠ‚ç‚¹
        if self.ancestors[0] == self:
            for node in self.node_list.nodes:
                node.ancestors.remove(self)  # ä»æ‰€æœ‰èŠ‚ç‚¹çš„ç¥–å…ˆåˆ—è¡¨ä¸­ç§»é™¤å½“å‰èŠ‚ç‚¹
                if node.fathers != []:  # å¦‚æœæœ‰çˆ¶èŠ‚ç‚¹
                    node.ancestors += node.fathers[0].ancestors  # å°†çˆ¶èŠ‚ç‚¹æ·»åŠ åˆ°ç¥–å…ˆåˆ—è¡¨ä¸­
                else:
                    node.fathers.append(node)  # å¦‚æœæ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼Œåˆ™å°†å½“å‰èŠ‚ç‚¹æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹åˆ—è¡¨ä¸­
                    node.ancestors.append(node)
        return self

class superData(superNode):
    def __init__(self, path='No path', task='task0', stage='defult', description='defult', node_list=None, sons=None, fathers=None, ancestors=None, content=None):
        super().__init__(node_list=node_list, sons=sons, fathers=fathers, ancestors=ancestors, content=content)
        if 'task' not in self.content:
            self.content['task'] = task  # ä»»åŠ¡åˆ—è¡¨
        if 'stage' not in self.content:
            self.content['stage'] = stage # ä»»åŠ¡é˜¶æ®µ
        if 'description' not in self.content:
            self.content['description'] = description # ä»»åŠ¡æè¿°
        if 'name' not in self.content:
            self.content['name'] = f"data_{self.content['task']}_{self.content['stage']}_{self.content['description']}" # æ•°æ®é›†åç§°ï¼Œè‡ªåŠ¨ç”Ÿæˆè·¯å¾„æ—¶éœ€è¦ä½¿ç”¨
        if 'path' not in self.content:
            self.content['path'] = path # æ•°æ®é›†è·¯å¾„
        if '*' in self.content['path']: # å¦‚æœä»¥*ç»“å°¾ï¼Œåˆ™ä¸ºè‡ªåŠ¨ç”Ÿæˆè·¯å¾„
            self.content['path'] = self.content['path'].replace('*', self.content['name']) # # ä¾‹å¦‚ï¼š./batch/* -> ./batch/batch_data_0, ./batch/*.json -> ./batch/batch_data_0.json
        if 'No path' not in self.content['path']:
            os.makedirs(self.content['path'], exist_ok=True)  # åˆ›å»ºç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™ä¸æŠ¥é”™

class superModel(superNode):
    def __init__(self, path='No path', task='task0', stage='defult', description='defult', node_list=None, sons=None, fathers=None, ancestors=None, content=None):
        super().__init__(node_list=node_list, sons=sons, fathers=fathers, ancestors=ancestors, content=content)
        if 'task' not in self.content:
            self.content['task'] = task  # ä»»åŠ¡åˆ—è¡¨
        if 'stage' not in self.content:
            self.content['stage'] = stage # ä»»åŠ¡é˜¶æ®µ
        if 'description' not in self.content:
            self.content['description'] = description # ä»»åŠ¡æè¿°
        if 'name' not in self.content:
            self.content['name'] = f"model_{self.content['task']}_{self.content['stage']}_{self.content['description']}" # æ•°æ®é›†åç§°ï¼Œè‡ªåŠ¨ç”Ÿæˆè·¯å¾„æ—¶éœ€è¦ä½¿ç”¨
        if 'path' not in self.content:
            self.content['path'] = path # æ•°æ®é›†è·¯å¾„
        if '*' in self.content['path']: # å¦‚æœä»¥*ç»“å°¾ï¼Œåˆ™ä¸ºè‡ªåŠ¨ç”Ÿæˆè·¯å¾„
            self.content['path'] = self.content['path'].replace('*', self.content['name']) # # ä¾‹å¦‚ï¼š./batch/* -> ./batch/batch_data_0, ./batch/*.json -> ./batch/batch_data_0.json
        if 'No path' not in self.content['path']:
            os.makedirs(self.content['path'], exist_ok=True)  # åˆ›å»ºç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™ä¸æŠ¥é”™

class superDistillation():
    def __init__(self,teacher_api='', student_model_path='No path', ckpt_dir_lora='No path', task='task0', raw_data_path="oss://ly-llm/data_self_evo/data_agent/train", prompt_template=None):
        # self.stages = ['raw', 'batch', 'distillation', 'train', 'val', 'gt', 'error_example', 'error_example_gt']
        # åˆå§‹åŒ–æ•°æ®é›†ç›®å½•
        self.current_dir = self.create_directories(['tmp'])
        self.data_dir = self.current_dir + '/data'  # æ•°æ®é›†ç›®å½•
        self.model_dir = self.current_dir + '/models'  # æ¨¡å‹ç›®å½•
        os.makedirs(self.data_dir, exist_ok=True)  # ç¡®ä¿æ•°æ®é›†ç›®å½•å­˜åœ¨
        os.makedirs(self.model_dir, exist_ok=True)  # ç¡®ä¿
        self.task = task  # ä»»åŠ¡åç§°
        if task is None:
            self.task = f"task{self.count_subfolders('Tasks')}"  # è®¡ç®—å½“å‰ç›®å½•ä¸‹çš„ä»»åŠ¡æ•°ç›®
        self.work_dir = f"{self.current_dir}/Tasks/{self.task}"  # å·¥ä½œç›®å½•
        os.makedirs(self.work_dir, exist_ok=True)  # ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
        self.cheacpoint_dir = f"{self.work_dir}/checkpoints"  # æ£€æŸ¥ç‚¹ç›®å½•
        os.makedirs(self.cheacpoint_dir, exist_ok=True)  # ç¡®ä¿æ£€æŸ¥ç‚¹ç›®å½•å­˜åœ¨
        self.raw_data_path = raw_data_path
        self.prompt_template = [prompt_template]
        self.errors = []
        self.root = superData(path='No path', task=self.task, stage='ROOT', description='root')
        self.datas = {
            # "ROOT":superData(path='No path', task=self.task, stage='ROOT', description='root'),
        }
        self.models = {
            "TEACHER": superModel(path='No path', task=self.task, stage='TEACHER', description='ds-v3-teacher', content={'api': teacher_api}, fathers=[self.root]),
            "BASE_LORA": superModel(path=ckpt_dir_lora, task=self.task, stage='BASE_LORA', description='oxs6-cheackpoint-60', fathers=[self.root]),
            "BASE": superModel(path=student_model_path, task=self.task, stage='BASE', description='qwen3-32b-fp32', fathers=[self.root]),
            # "base_trian": superModel(path=ckpt_dir_lora, task=self.task, stage='TRAIN_LORA', description='trained-lr=3e-5-epoch=1'),
        }
        print(f"ä»»åŠ¡åç§°: {self.task}")
        print(f"å½“å‰å·¥ä½œç›®å½•: {self.current_dir}")
        print(f"æ•°æ®é›†ç›®å½•: {self.data_dir}")
        print(f"æ¨¡å‹ç›®å½•: {self.model_dir}")
        print(f"å·¥ä½œç›®å½•: {self.work_dir}")
        print(f"æ£€æŸ¥ç‚¹ç›®å½•: {self.cheacpoint_dir}")
        print(f"åŸå§‹æ•°æ®è·¯å¾„: {self.raw_data_path}")

    def save_checkpoint(self, path, cp_name, stage_single=True):
        """
        ä¿å­˜å½“å‰ä»»åŠ¡çš„æ£€æŸ¥ç‚¹æ•°æ®åˆ°æŒ‡å®šè·¯å¾„ã€‚
        """
        # å¯¹äºå­˜åœ¨äºdataså’Œmodelsä¸­çš„æ¯ä¸ªstageï¼Œå¦‚æœæŸé˜¶æ®µæœ‰å¤šä¸ªï¼Œåˆ™ä»…ä¿ç•™è®°å½•åœ¨æ¡ˆçš„èŠ‚ç‚¹ï¼Œåˆ é™¤å…¶ä»–èŠ‚ç‚¹ã€‚
        if stage_single:
            for stage in list(self.datas.keys()):
                for node in self.root.node_list.nodes:
                    if stage == node.content['stage']:
                        if self.datas[stage] != node:
                            node.delete_node()  # åˆ é™¤å½“å‰æ•°æ®é›†èŠ‚ç‚¹
            for stage in list(self.models.keys()):
                for node in self.root.node_list.nodes:
                    if stage == node.content['stage']:
                        if self.models[stage] != node:
                            node.delete_node()  # åˆ é™¤å½“å‰æ•°æ®é›†èŠ‚ç‚¹
        num = self.count_files_with_pattern(path, f"checkpoint_{self.task}_{cp_name}")  # ç»Ÿè®¡å½“å‰æ£€æŸ¥ç‚¹æ–‡ä»¶æ•°é‡
        self.root.save_all(path+f"/checkpoint_{self.task}_{cp_name}_{num}.json")  # ä¿å­˜æ•°æ®é›†æ—è°±
        print(f"ä¿å­˜æ£€æŸ¥ç‚¹æ•°æ®æˆåŠŸ: {path}"+f"/checkpoint_{self.task}_{cp_name}_{num}.json")

    def load_cheakpoint(self, path):
        """
        ä»æŒ‡å®šè·¯å¾„åŠ è½½æ£€æŸ¥ç‚¹æ•°æ®ã€‚
        """
        cp = superData.load_all(self, path)  # ä»æ–‡ä»¶ä¸­åŠ è½½æ•°æ®é›†æ—è°±
        for node in cp.node_list.nodes:
            if 'ROOT' in node.content['stage']:
                self.root = node
            elif 'data' in node.content['name']:
                self.datas[node.content['stage']] = node
            elif 'model' in node.content['name']:
                self.models[node.content['stage']] = node
        print(f"åŠ è½½æ£€æŸ¥ç‚¹æ•°æ®æˆåŠŸ: {path}")

    @staticmethod
    def count_files_with_pattern(path, pattern):
        """ç»Ÿè®¡åŒ…å«æŒ‡å®šæ¨¡å¼çš„æ–‡ä»¶æ•°é‡"""
        # ä½¿ç”¨é€šé…ç¬¦æœç´¢
        search_pattern = os.path.join(path, f"*{pattern}*")
        matching_files = glob.glob(search_pattern)
        
        return len(matching_files)
    
    def count_subfolders(self, folder_name='Tasks'):
        """
        è¿”å› self.current_dir + '/Tasks' ç›®å½•ä¸‹çš„æ–‡ä»¶å¤¹æ•°ç›®
        """
        tasks_dir = os.path.join(self.data_dir, folder_name)
        if not os.path.exists(tasks_dir):
            print(f"{tasks_dir} ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            os.makedirs(tasks_dir, exist_ok=True)  # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºç›®å½•
            print(f"{tasks_dir} åˆ›å»ºæˆåŠŸ")

        return len([item for item in os.listdir(tasks_dir) if os.path.isdir(os.path.join(tasks_dir, item))])

    def create_directories(self, directories):
        # è·å–å¹¶æ‰“å°å½“å‰å·¥ä½œç›®å½•
        current_dir = os.getcwd()
        while current_dir == '\n':
            current_dir = input(f"å½“å‰æ–‡ä»¶å¤¹ä½ç½®: {current_dir}æ˜¯å¦æ­£ç¡®ï¼Ÿæ­£ç¡®è¯·å›è½¦ï¼Œä¸æ­£ç¡®è¯·è¾“å…¥æ­£ç¡®è·¯å¾„ï¼Œè¾“å…¥exitç»“æŸã€‚")
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(current_dir):
                print(f"å½“å‰è·¯å¾„ {current_dir} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
                continue
            if current_dir.lower() == 'exit':
                print("ç¨‹åºç»“æŸï¼Œåˆ›å»ºç›®å½•å¤±è´¥ï¼Œè¯·è°ƒç”¨create_directories(self, directories)æˆ–æ‰‹åŠ¨åˆ›å»ºã€‚")
                return
        # è·³è¿‡è·¯å¾„å‰åçš„ç©ºæ ¼
        current_dir = current_dir.strip()
        # åˆ›å»ºç›®å½•
        print("\nå¼€å§‹åˆ›å»ºç›®å½•...")
        for dir_name in directories:
            dir_path = os.path.join(current_dir, dir_name)
            try:
                # ä½¿ç”¨ exist_ok=True é¿å…ç›®å½•å·²å­˜åœ¨æ—¶æŠ¥é”™
                os.makedirs(dir_path, exist_ok=True)
                print(f"âœ“ å·²åˆ›å»ºç›®å½•: {dir_name}")
            except Exception as e:
                print(f"âœ— åˆ›å»ºç›®å½• {dir_name} å¤±è´¥: {e}")

        print("\nç›®å½•åˆ›å»ºå®Œæˆï¼")

        # åˆ—å‡ºå½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        print("\nå½“å‰ç›®å½•å†…å®¹:")
        for item in os.listdir(current_dir):
            item_path = os.path.join(current_dir, item)
            if os.path.isdir(item_path):
                print(f"ğŸ“ {item}/")
            else:
                print(f"ğŸ“„ {item}")
        return current_dir

    def action_example(self, data_example):
        """
        ç¤ºä¾‹æ“ä½œï¼Œæ‰“å°æ•°æ®é›†ç¤ºä¾‹å†…å®¹ã€‚
        """
        data_example.save_all()
        data_new = superData(path=os.path.join(self.data_dir, 'raw/*'), task=self.task, stage='RAW', description='nums=3e4+type=multi_step', fathers=[], content={"from_path": 'from_example'})  # åˆ›å»ºåŸå§‹æ•°æ®é›†å¯¹è±¡
        self.fun_example(data_example.content["path"], data_new)
        return data_new

    def get_raw(self, from_path):
        """
        ä»æŒ‡å®šè·¯å¾„åŠ è½½åŸå§‹æ•°æ®é›†ã€‚
        """
        raw_data = superData(path=os.path.join(self.data_dir, 'raw/*/'), task=self.task, stage='RAW', description='', fathers=[self.root], content={"from_path": from_path})  # åˆ›å»ºåŸå§‹æ•°æ®é›†å¯¹è±¡
        self.datas[raw_data.content['stage']] = raw_data  # å°†åŸå§‹æ•°æ®é›†æ·»åŠ åˆ°æ•°æ®é›†ä¸­
        self.execute_ossutil_method1(from_path, raw_data.content["path"]) # ä»OSSä¸‹è½½åŸå§‹æ•°æ®
        self.save_checkpoint(self.cheacpoint_dir, 'get_raw')  # ä¿å­˜å½“å‰ä»»åŠ¡è¿›åº¦
    
    def raw2batch(self, raw_data, model_name='deepseek-v3', ratio=[0, 1], sample_num=1e2, single_file_nums=1e2, ans_num=1):
        """
        å°†åŸå§‹æ•°æ®é›†è½¬æ¢ä¸ºæ‰¹å¤„ç†æ•°æ®é›†ã€‚
        """
        from tools.raw2batch import raw2batch
        # åˆ›å»ºæ‰¹å¤„ç†æ•°æ®é›†å¯¹è±¡
        batch_data = superData(path=self.data_dir + '/batch/*', task=self.task, stage='BATCH', description=f"{sample_num}-{single_file_nums}-{ratio[0]}-{ratio[1]}-{model_name}", fathers=[raw_data])  
        self.datas[batch_data.content['stage']] = batch_data  # å°†åŸå§‹æ•°æ®é›†æ·»åŠ åˆ°æ•°æ®é›†ä¸­
        # è°ƒç”¨func1æ–¹æ³•ï¼Œå°†åŸå§‹æ•°æ®é›†è½¬æ¢ä¸ºæ‰¹å¤„ç†æ•°æ®é›†
        raw2batch(
            raw_data=raw_data,
            batch_data = batch_data,
            model_name=model_name,
            ratio=ratio, 
            sample_num=sample_num, 
            single_file_nums=single_file_nums,
            ans_num=ans_num
        )  # é»˜è®¤ä½¿ç”¨func1æ–¹æ³•
        self.save_checkpoint(self.cheacpoint_dir, 'raw2batch')  # ä¿å­˜å½“å‰ä»»åŠ¡è¿›åº¦
    
    def batch2distill(self, batch_data, thread_count=2, type='batch', continue_flag=False):
        from tools.batch2distill import batch2distill, multi_thread_batch2distill
        from tools.single2distill import single2distill, multi_thread_single2distill
        """        
        å°†æ‰¹å¤„ç†æ•°æ®é›†è½¬æ¢ä¸ºè’¸é¦æ•°æ®é›†ã€‚
        """
        distill_data = superData(path=self.data_dir + '/distillation/*', task=self.task, stage='DISTILLATION', description=f"{type}{thread_count}thread", fathers=[batch_data])  # åˆ›å»ºè’¸é¦æ•°æ®é›†å¯¹è±¡
        distill_error_data = superData(path=self.data_dir + '/distillation_error/*', task=self.task, stage='DISTILLATION_ERROR', description=f"{type}{thread_count}thread", fathers=[batch_data])  # åˆ›å»ºè’¸é¦é”™è¯¯æ•°æ®é›†å¯¹è±¡
        self.datas[distill_data.content['stage']] = distill_data  # å°†è’¸é¦æ•°æ®é›†æ·»åŠ åˆ°æ•°æ®é›†ä¸­
        self.datas[distill_error_data.content['stage']] = distill_error_data  # å°†è’¸é¦é”™è¯¯æ•°æ®
        if type == 'single':
            if thread_count == 1:
                single2distill(
                    batch_path=batch_data.content['path'],
                    distill_path=distill_data.content['path'],
                    continue_flag=continue_flag,  # æ˜¯å¦ç»§ç»­ä¸Šæ¬¡çš„è½¬æ¢
                )
            else:
                multi_thread_single2distill(
                    batch_path=batch_data.content['path'],
                    distill_path=distill_data.content['path'],
                    error_file_path=distill_error_data.content['path'],
                    thread_count=thread_count,  # é»˜è®¤ä½¿ç”¨2ä¸ªçº¿ç¨‹è¿›è¡Œæ‰¹å¤„ç†æ•°æ®é›†è½¬æ¢
                    continue_flag=continue_flag  # æ˜¯å¦ç»§ç»­ä¸Šæ¬¡çš„è½¬æ¢
                )
        elif type == 'batch':  # é»˜è®¤ä½¿ç”¨batch2distillæ–¹æ³•è¿›è¡Œæ‰¹å¤„ç†æ•°æ®é›†è½¬æ¢
            if thread_count == 1:
                batch2distill(
                    batch_path=batch_data.content['path'],
                    distill_path=distill_data.content['path'],
                    error_file_path=distill_error_data.content['path'],
                    start=0,
                    end=2  # é»˜è®¤ä½¿ç”¨å…¨éƒ¨æ•°æ®  
                    )
            else:
                multi_thread_batch2distill(
                    batch_path=batch_data.content['path'],
                    distill_path=distill_data.content['path'],
                    error_file_path=distill_error_data.content['path'],
                    thread_count=thread_count  # é»˜è®¤ä½¿ç”¨2ä¸ªçº¿ç¨‹è¿›è¡Œæ‰¹å¤„ç†æ•°æ®é›†è½¬æ¢
                )  # è°ƒç”¨batch2distillæ–¹æ³•
        else:
            print(f"æœªå®šä¹‰çš„è½¬æ¢ç±»å‹: {type}ï¼Œè¯·ä½¿ç”¨'single'æˆ–'batch'ã€‚")
            del self.datas[distill_data.content['stage']]  # åˆ é™¤è’¸é¦æ•°æ®é›†
            del self.datas[distill_error_data.content['stage']]  # åˆ é™¤è’¸
        self.save_checkpoint(self.cheacpoint_dir, 'batch2distill')  # ä¿å­˜å½“å‰ä»»åŠ¡è¿›åº¦
        
    def distill2train(self, raw_data, batch_data, distill_data):
        from tools.distill2train import distill2train
        """
        å°†æ‰¹å¤„ç†æ•°æ®é›†è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®é›†ã€‚
        """
        # åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†
        train_data = superData(path=self.data_dir + '/train/*', stage='TRAINING', discribe='Train data from batch and distillation data', fathers=[raw_data, batch_data, distill_data])  # åˆ›å»ºè®­ç»ƒæ•°æ®é›†å¯¹è±¡
        test_data = superData(path=self.data_dir + '/test/*', stage='TESTING', discribe='Test data from batch and distillation data', fathers=[raw_data, batch_data, distill_data])  # åˆ›å»ºæµ‹è¯•æ•°æ®é›†å¯¹è±¡
        self.datas[train_data.content['stage']] = train_data  # å°†è®­ç»ƒæ•°æ®é›†æ·»åŠ åˆ°æ•°æ®é›†ä¸­
        self.datas[test_data.content['stage']] = test_data  # å°†æµ‹è¯•æ•°æ®é›†æ·»åŠ åˆ°æ•°æ®é›†ä¸­
        distill2train(
            raw_path=raw_data.path,
            batch_path=batch_data.path,
            distill_path=distill_data.path,
            train_path=train_data.path,
            test_path=test_data.path,
            test_ratio=0.05,  # é»˜è®¤ä½¿ç”¨0.05çš„æµ‹è¯•æ¯”ä¾‹
            raw_ratio=0.  # é»˜è®¤ä½¿ç”¨0.1çš„åŸå§‹æ•°æ®æ¯”ä¾‹
        )
        self.save_checkpoint(self.cheacpoint_dir, 'distill2train')  # ä¿å­˜å½“å‰ä»»åŠ¡è¿›åº¦

    def train(self, train_data, base, base_lora):
        """
        ä½¿ç”¨è’¸é¦æ•°æ®é›†è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ã€‚
        """
        from tools.train import train
        self.models['final_student'] = self.model_dir + '/train_models/'  # æ›´æ–°å­¦ç”Ÿæ¨¡å‹è·¯å¾„
        trained_model = superModel(path=self.model_dir + '/train_models/*', stage='TRAINED', discribe='Trianed student model from distillation data', fathers=[train_data, base, base_lora])  # åˆ›å»ºè®­ç»ƒåçš„å­¦ç”Ÿæ¨¡å‹æ•°æ®é›†å¯¹è±¡
        self.models[trained_model.content['stage']] = trained_model  # å°†åŸå§‹æ•°æ®é›†æ·»åŠ åˆ°æ•°æ®é›†ä¸­
        train(
            model_path=base.content['path'],  # å­¦ç”Ÿæ¨¡å‹è·¯å¾„
            ckpt_dir_lora=base_lora.content['path'],  # LoRAæ£€æŸ¥ç‚¹ç›®å½•ï¼Œæš‚æ—¶æœªå®šä¹‰
            dataset=train_data.content['path'],  # è’¸é¦æ•°æ®é›†è·¯å¾„
            output_dir=trained_model.content['path'],  # è¾“å‡ºç›®å½•
        )
        print(f"Training student model at {base.content['path']} and {base_lora.content['path']} with data from {train_data.content['path']}")
        self.save_checkpoint(self.cheacpoint_dir, 'train')  # ä¿å­˜å½“å‰ä»»åŠ¡è¿›åº¦

    @staticmethod
    def clear_folder(folder_path):
        for filename in os.listdir(folder_path):
            file_path = os.path.join(folder_path, filename)
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.remove(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)

    @staticmethod
    def super_split(text, separators):
        import re
        # text = "some text```sql SELECT * FROM table```python print('hello')``` more text"
        # separators = ['```sql', '```python', '```']

        # åˆ›å»ºæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        pattern = '|'.join(re.escape(sep) for sep in separators)
        result = re.split(pattern, text)

        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
        return [item.strip() for item in result if item.strip()]
        
    @staticmethod
    def data_load(data_path, layers = 0, excludes=None, filters=None, mode=None):
        """
        ä»æŒ‡å®šè·¯å¾„åŠ è½½æ•°æ®é›†ã€‚æ”¯æŒjsonã€jsonlæ–‡ä»¶æˆ–åŒ…å«json/jsonlæ–‡ä»¶çš„æ–‡ä»¶å¤¹ã€‚
        è¿”å›ï¼šlistï¼ˆæ¯æ¡æ•°æ®ä¸ºdictï¼‰
        """
        import glob

        def load_json(fp):
            with open(fp, 'r', encoding='utf-8') as f:
                return json.load(f)

        def load_jsonl(fp):
            data = []
            with open(fp, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        data.append(json.loads(line))
            return data

        all_data = []

        # OSS è·¯å¾„å¤„ç†
        if data_path.startswith("oss://"):
            superDistillation.execute_ossutil_method1(data_path, os.path.join(superDistillation.current_dir, 'tmp'))
            data_path = os.path.join(superDistillation.current_dir, 'tmp')

        # æ–‡ä»¶å¤¹
        if os.path.isdir(data_path):
            files = glob.glob(os.path.join(data_path, "*.json")) + glob.glob(os.path.join(data_path, "*.jsonl"))
            while layers > 0:
                # é€’å½’åŠ è½½æŒ‡å®šå±‚æ•°çš„å­ç›®å½•
                files = glob.glob(os.path.join(data_path, "*"))
                for fp in files:
                    fp_ = os.path.join(data_path, fp)
                    if os.path.isdir(fp_):
                        files += glob.glob(os.path.join(fp_, "*.json")) + glob.glob(os.path.join(fp_, "*.jsonl"))
                layers -= 1
            files = [file for file in files if file.endswith('.json') or file.endswith('.jsonl')]
            # files = glob.glob(os.path.join(data_path, "*.json")) + glob.glob(os.path.join(data_path, "*.jsonl"))
            for fp in tqdm(files):
                if excludes and any(exclude in fp for exclude in excludes):
                    print(f"è·³è¿‡æ–‡ä»¶ {fp}ï¼Œå› ä¸ºå®ƒä¸ç¬¦åˆé¢„æœŸï¼š{excludes}")
                    continue
                if filters and any(filter not in fp for filter in filters):
                    print(f"è·³è¿‡æ–‡ä»¶ {fp}ï¼Œå› ä¸ºå®ƒä¸ç¬¦åˆé¢„æœŸï¼š{filter}")
                    continue
                if fp.endswith('.json'):
                    d = load_json(fp)
                    if isinstance(d, list):
                        all_data.extend(d)
                    else:
                        all_data.append(d)
                elif fp.endswith('.jsonl'):
                    all_data.extend(load_jsonl(fp))
        # å•æ–‡ä»¶
        elif os.path.isfile(data_path):
            if mode == 'json' or data_path.endswith('.json'):
                d = load_json(data_path)
                if isinstance(d, list):
                    all_data.extend(d)
                else:
                    all_data.append(d)
            elif mode == 'jsonl' or data_path.endswith('.jsonl'):
                all_data.extend(load_jsonl(data_path))
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {data_path}")
        else:
            raise FileNotFoundError(f"æ•°æ®é›†è·¯å¾„ {data_path} ä¸å­˜åœ¨ï¼")

        return all_data

    @staticmethod
    def data_save(data, save_path, mode=None, save_type='w'):
        """
        ä¿å­˜æ•°æ®åˆ°æŒ‡å®šè·¯å¾„ã€‚æ”¯æŒä¿å­˜ä¸º json æˆ– jsonl æ ¼å¼ã€‚
        å‚æ•°:
            data: list æˆ– dictï¼Œå¾…ä¿å­˜çš„æ•°æ®
            save_path: strï¼Œä¿å­˜è·¯å¾„
            mode: 'json' æˆ– 'jsonl'
        """
        import json
        if save_type not in ['w', 'a']:
            raise ValueError("save_type åªèƒ½ä¸º 'w' æˆ– 'a'ï¼Œåˆ†åˆ«è¡¨ç¤ºå†™å…¥å’Œè¿½åŠ æ¨¡å¼ã€‚")
        elif save_type == 'a' and not os.path.exists(save_path):
            print(f"æ–‡ä»¶ {save_path} ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶ã€‚")
        
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        if not mode:
            mode = 'json' if save_path.endswith('.json') else 'jsonl' if save_path.endswith('.jsonl') else None

        if mode == 'json':
            with open(save_path, save_type, encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=4)
        elif mode == 'jsonl':
            with open(save_path, save_type, encoding='utf-8') as f:
                if isinstance(data, dict):
                    f.write(json.dumps(data, ensure_ascii=False) + '\n')
                else:
                    for item in data:
                        f.write(json.dumps(item, ensure_ascii=False) + '\n')
        else:
            raise ValueError("mode åªèƒ½ä¸º 'json' æˆ– 'jsonl'")

    @staticmethod
    def jsonl_json_swift(path, mode='json2jsonl'):
        """
        å°† jsonl æ–‡ä»¶è½¬æ¢ä¸º json æ–‡ä»¶ï¼Œæˆ–å°† json æ–‡ä»¶è½¬æ¢ä¸º jsonl æ–‡ä»¶ã€‚
        """
        import json
        import os

        if not os.path.exists(path):
            raise FileNotFoundError(f"æ–‡ä»¶ {path} ä¸å­˜åœ¨ï¼")

        if mode == 'json2jsonl':
            # å°† json æ–‡ä»¶è½¬æ¢ä¸º jsonl æ–‡ä»¶
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            jsonl_path = path.replace('.jsonl', '.json').replace('.json', '.jsonl')
            with open(jsonl_path, 'w', encoding='utf-8') as f:
                for item in data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            print(f"å·²å°† {path} è½¬æ¢ä¸º {jsonl_path}")
            return jsonl_path
        elif mode == 'jsonl2json':
            # å°† jsonl æ–‡ä»¶è½¬æ¢ä¸º json æ–‡ä»¶
            with open(path, 'r', encoding='utf-8') as f:
                data = [json.loads(line.strip()) for line in f if line.strip()]
            json_path = path.replace('.jsonl', '.json')
            with open(json_path, 'w', encoding='utf-8') as f:   
                json.dump(data, f, ensure_ascii=False, indent=4)
            print(f"å·²å°† {path} è½¬æ¢ä¸º {json_path}")
            return json_path
        else:
            raise ValueError("mode åªèƒ½ä¸º 'json2jsonl' æˆ– 'jsonl2json'ï¼Œåˆ†åˆ«è¡¨ç¤ºå°† json è½¬æ¢ä¸º jsonl æˆ–å°† jsonl è½¬æ¢ä¸º jsonã€‚")

    def execute_ossutil_method1(self, data_from, data_to):
        """ä½¿ç”¨subprocess.run()æ‰§è¡Œossutilå‘½ä»¤"""
        command = [
            "ossutil",
            "cp",
            "-r",
            data_from,
            data_to,
            "-c",
            self.current_dir+"/script/oss2xy.sh"
        ]
        if data_from.split('/')[-1] in os.listdir(data_to):
            print(f"æ•°æ® {data_from} å·²ç»å­˜åœ¨äº {data_to}ï¼Œè·³è¿‡æ‹‰å–ã€‚")
            return 0
        try:
            # æ‰§è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
            print('å¼€å§‹ä» OSS æ‹‰å–æ•°æ®')
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                check=True  # å¦‚æœå‘½ä»¤å¤±è´¥ä¼šæŠ›å‡ºå¼‚å¸¸
            )
            
            print("å‘½ä»¤æ‰§è¡ŒæˆåŠŸï¼")
            print("æ ‡å‡†è¾“å‡º:", result.stdout)
            if result.stderr:
                print("æ ‡å‡†é”™è¯¯:", result.stderr)
            
            return result.returncode
            
        except subprocess.CalledProcessError as e:
            print(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼è¿”å›ç : {e.returncode}")
            print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            return e.returncode
